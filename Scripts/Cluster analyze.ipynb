{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set path to the folder of used python files\n",
    "'''\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(0, '/Users/lynnjiang/liuGit/Pybook/Clinic-Analysis/Scripts/Data_Cleaning')\n",
    "from Abstract import Abstract\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.cluster as cluster\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = Abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>9977</th>\n",
       "      <th>9978</th>\n",
       "      <th>9979</th>\n",
       "      <th>9981</th>\n",
       "      <th>9982</th>\n",
       "      <th>9983</th>\n",
       "      <th>9984</th>\n",
       "      <th>9988</th>\n",
       "      <th>9995</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   10   11   12   13   14   15   16   17   18  ...   9977  9978  \\\n",
       "0           2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1           3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2           4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3           5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4           6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   9979  9981  9982  9983  9984  9988  9995  9999  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2010 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = 'procedures'\n",
    "user_vec = aa.read_data('temp/USER_VECTORS/%s_uservectors' % data_name)\n",
    "user_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the first coloumn\n",
    "# user_vec.rename(columns={'Unnamed: 0':'SUBJECT_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get 10 randomly selected sub datasets\n",
    "for i in range(10):\n",
    "    aa.write2file(user_vec.sample(frac=0.05), 'USER_VECTORS/%s_sample%d'% (data_name,i))\n",
    "# user_vec.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.stats import ks_2samp, chisquare\n",
    "import sklearn.cluster as cluster\n",
    "import time\n",
    "def cluster_alg(data, alg, args, kwds):\n",
    "    start_time = time.time()\n",
    "    labels = alg(*args, **kwds).fit_predict(data)\n",
    "    end_time = time.time()\n",
    "    labels_count = Counter(labels)\n",
    "    print(\"Time spent: %.2f s \\nClusters: %s \\n \" %(end_time-start_time, labels_count))\n",
    "    return labels, labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return comparising results of two distributions using ks2samp\n",
    "def ks2samp(col, arraya, arrayb):\n",
    "    result = ks_2samp(arraya, arrayb)\n",
    "    return col, result.statistic, result.pvalue\n",
    "\n",
    "\n",
    "def get_cluster_stats(alg, params, data_name):\n",
    "    \n",
    "    all_stats_df = pd.DataFrame()\n",
    "    all_labels_count = []\n",
    "    for i in range(10):\n",
    "        sample_i = aa.read_data('temp/USER_VECTORS/%s_sample%d' % (data_name,i))\n",
    "        ## Specific cluster algorithm\n",
    "        labels, labels_count = cluster_alg(sample_i.iloc[:,1:], alg, (), params)\n",
    "        all_labels_count.append(list(labels_count.values()))\n",
    "        label_values = list(set(labels))\n",
    "        pred_df = pd.concat([sample_i.iloc[:,1:], pd.Series(labels)], axis=1)\n",
    "    \n",
    "        ## Split feature data into two parts based on predicted labels for analyzing distributions from two parts for each feature\n",
    "        pred_0_df, pred_1_df = [x for _, x in pred_df.groupby(pred_df[0] == label_values[0])]\n",
    "        columns = sample_i.columns[1:]\n",
    "\n",
    "        cluster_stas_list = list(map(lambda col: ks2samp(col,pred_0_df[col], pred_1_df[col]), columns))\n",
    "        cluster_stats_df = pd.DataFrame(cluster_stas_list, columns=['CODE', 'STATISTIC', 'PVALUE'])\n",
    "        all_stats_df = all_stats_df.append(cluster_stats_df)\n",
    "    \n",
    "    # Get average statistics of all sub dataset\n",
    "    pure_stats_df = all_stats_df.groupby('CODE')['STATISTIC','PVALUE'].agg('mean')\n",
    "    pure_stats_df = pure_stats_df.reset_index().sort_values(by='PVALUE')\n",
    "    aa.write2file(pure_stats_df,'CLUSTER_STATISTICS/%s_%s_ks2' % (data_name,alg.__name__))\n",
    "    avg_labels_count = dict(pd.DataFrame(all_labels_count).mean())\n",
    "    print('Cluster counts: %s\\nNumbers of features with p<0.05: %d' % (avg_labels_count, len(pure_stats_df[pure_stats_df['PVALUE']<=0.05])))\n",
    "    return pure_stats_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 1968 \n",
      "Time spent: 30.51 s \n",
      "Clusters: Counter({-1: 1937, 1: 15, 0: 9, 2: 7}) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "## test one time\n",
    "# alg = cluster.SpectralClustering\n",
    "# params = {'n_clusters':2, 'affinity': 'rbf'}\n",
    "# sample_i = aa.read_data('temp/USER_VECTORS/%s_sample%d' % ('diag',0))\n",
    "# labels = cluster_alg(sample_i.iloc[:,1:], alg, (), params)\n",
    "\n",
    "\n",
    "# def test(data_name='diag',alg=cluster.DBSCAN,params={'eps':10}):\n",
    "def test(data_name='prescriptions',alg=cluster.DBSCAN,params={'eps':7}):\n",
    "    sample_i = aa.read_data('temp/USER_VECTORS/%s_sample%d' % (data_name,1))\n",
    "    cluster_alg(sample_i.iloc[:,1:], alg, (), params)\n",
    "#     return sample_i\n",
    "  \n",
    "test()\n",
    "\n",
    "## test code\n",
    "# for i in range(10,110,10):\n",
    "#     test(params={'eps':i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 1.82 s \n",
      "Clusters: Counter({0: 1504, 1: 607}) \n",
      " \n",
      "Time spent: 1.49 s \n",
      "Clusters: Counter({0: 1526, 1: 585}) \n",
      " \n",
      "Time spent: 1.77 s \n",
      "Clusters: Counter({1: 1511, 0: 600}) \n",
      " \n",
      "Time spent: 1.52 s \n",
      "Clusters: Counter({0: 1539, 1: 572}) \n",
      " \n",
      "Time spent: 1.78 s \n",
      "Clusters: Counter({0: 1543, 1: 568}) \n",
      " \n",
      "Time spent: 2.25 s \n",
      "Clusters: Counter({0: 1534, 1: 577}) \n",
      " \n",
      "Time spent: 2.00 s \n",
      "Clusters: Counter({1: 1486, 0: 625}) \n",
      " \n",
      "Time spent: 1.85 s \n",
      "Clusters: Counter({0: 1497, 1: 614}) \n",
      " \n",
      "Time spent: 1.77 s \n",
      "Clusters: Counter({0: 1520, 1: 591}) \n",
      " \n",
      "Time spent: 1.73 s \n",
      "Clusters: Counter({0: 1489, 1: 622}) \n",
      " \n",
      "Cluster counts: {0: 1233.6, 1: 877.4}\n",
      "Numbers of features with p<0.05: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get all statistics\n",
    "## AgglomerativeClustering,{'n_clusters':2, 'linkage':'ward'}\n",
    "data_name = 'procedures'\n",
    "cluster_stats = get_cluster_stats(cluster.KMeans, {'n_clusters':2}, data_name)\n",
    "len(cluster_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_stats[cluster_stats['PVALUE']<=0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stats_df.head()\n",
    "pure_stats_df = all_stats_df.groupby('CODE')['STATISTIC','PVALUE'].agg('mean')\n",
    "pure_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure_stats_df = pure_stats_df.reset_index()\n",
    "# pure_stats_df.head()\n",
    "aa.write2file(pure_stats_df.sort_values(by='PVALUE'),'CLUSTER_STATISTICS/diag_kmeans_ks2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kmeans\n",
    "diag_labels = cluster_alg(dia_sample_0.iloc[:,1:], cluster.KMeans, (), {'n_clusters':2})\n",
    "diag_pred_df = pd.concat([dia_sample_0.iloc[:,1:], pd.Series(diag_labels)], axis=1)\n",
    "diag_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split feature data into two parts based on predicted labels for analyzing distributions from two parts for each feature\n",
    "diag_pred0_df, diag_pred1_df = [x for _, x in diag_pred_df.groupby(diag_pred_df[0] == 1)]\n",
    "diag_pred0_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return comparising results of two distributions using ks2samp\n",
    "def ks2samp(col, arraya, arrayb):\n",
    "    result = ks_2samp(arraya, arrayb)\n",
    "    return col, result.statistic, result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_columns = dia_sample_0.iloc[:,1:].columns\n",
    "# result = (ks_2samp(diag_pred0_df[diag_columns[0]],diag_pred1_df[diag_columns[0]]))\n",
    "diag_ks2samp_list = list(map(lambda col: ks2samp(col,diag_pred0_df[col], diag_pred1_df[col]), diag_columns))\n",
    "diag_ks2samp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cluster_stats= pd.DataFrame(diag_ks2samp_list, columns=['DIAG_IDC9_CODE', 'STATISTIC', 'PVALE'])\n",
    "diag_cluster_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare([2,3,11,0,2],[2,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cluster_stats.sort_values(by='PVALE')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(123456)\n",
    "x = np.random.normal(0, 1, 1000)\n",
    "y = np.random.normal(0, 1, 800)\n",
    "print('a', ks_2samp(x, y))\n",
    "# print('b', ks_2samp(y,x))\n",
    "\n",
    "# print(chisquare(x, f_exp=y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}\n",
    "## Get clusters\n",
    "def plot_clusters(data, algorithm, args, kwds):\n",
    "    start_time = time.time()\n",
    "    labels = algorithm(*args, **kwds).fit_predict(data)\n",
    "    end_time = time.time()\n",
    "    palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "    colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "\n",
    "## UMP transform\n",
    "#     ump_embed = umap.UMAP().fit_transform(data)\n",
    "## PCA transform    \n",
    "    pca = PCA(n_components=2).fit(data)\n",
    "    pca_2d = pca.transform(data)\n",
    "    \n",
    "    plt.scatter(pca_2d[:,0], pca_2d[:,1], c=colors, **plot_kwds)\n",
    "    frame = plt.gca()\n",
    "    frame.axes.get_xaxis().set_visible(False)\n",
    "    frame.axes.get_yaxis().set_visible(False)\n",
    "    plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=24)\n",
    "    print('Clustering took {:.2f} s'.format(end_time - start_time))\n",
    "    print(('Cluster counter: %s') % Counter(labels))\n",
    "    aa.write2file(pd.DataFrame({'LABEL': labels}),'CLUSTERS/lab_%s' % str(algorithm.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(user_vec.iloc[:,1:], cluster.KMeans, (), {'n_clusters':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(user_vec.iloc[:,1:], cluster.AffinityPropagation, (), {'preference':-5.0, 'damping':0.95})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "def ump(data):\n",
    "    \n",
    "    ump_embed = umap.UMAP().fit_transform(data)\n",
    "    plt.figure('ump')\n",
    "    plt.scatter(ump_embed[:,0], ump_embed[:,1])\n",
    "    plt.show()\n",
    "    \n",
    "# from sklearn.datasets import load_digits\n",
    "\n",
    "# digits = load_digits()\n",
    "\n",
    "embedding = umap.UMAP().fit_transform(user_finaldf)\n",
    "\n",
    "actual_labels['LABEL'] = actual_labels['LABEL'].astype(int)\n",
    "actual_labels['PREDICTED']=y_pred\n",
    "actual_labels['X0']=embedding[:,0]\n",
    "actual_labels['X1']=embedding[:,1]\n",
    "# actual_labels[:10]\n",
    "# pd.concat([y_pred, actual_labels['LABEL'].astype(int)],axis=1).head()\n",
    "# embedding.tolist()\n",
    "true_X = actual_labels[actual_labels['LABEL']==0]\n",
    "false_X = actual_labels[actual_labels['LABEL']==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
